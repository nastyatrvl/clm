{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (AutoTokenizer, GPT2Tokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, AutoModelForCausalLM, GPT2LMHeadModel, AutoModelWithLMHead,\n",
    "                         DataCollatorForLanguageModeling, pipeline)\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data (Emotion dataset by Twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset emotion (/home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e115570f8d64b108312715187d4f7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion_dataset = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-0725efdf174a2254.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-e834b2ee31382d6e.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-500c8bcbfa97f2d6.arrow\n"
     ]
    }
   ],
   "source": [
    "emotion_dataset = emotion_dataset.map(lambda record: {'text': 'sadness ' + record['text']} if record['label']==0 else \\\n",
    "                          ({'text': 'joy ' + record['text']} if record['label']==1 else \\\n",
    "                          ({'text': 'love ' + record['text']} if record['label']==2 else \\\n",
    "                          ({'text': 'anger ' + record['text']} if record['label']==3 else \\\n",
    "                          ({'text': 'fear ' + record['text']} if record['label']==4 else \\\n",
    "                           {'text': 'surprise ' + record['text']})\n",
    "                          ) \n",
    "                          )\n",
    "                          )\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'sadness i didnt feel humiliated', 'label': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(record):\n",
    "    return tokenizer(record[\"text\"], padding = \"max_length\", truncation = True, max_length = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a5747f92a343b6812f6d481ec50f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b76d85964cd477b89501bf274a34bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783f9252478e4c8695e339884e44b535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion_dataset_tokenized = emotion_dataset.map(tokenize_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dataset_tokenized = emotion_dataset_tokenized.remove_columns(['text']).rename_column('label', 'labels').with_format('torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_train_dataset, emotion_eval_dataset = emotion_dataset_tokenized[\"train\"], emotion_dataset_tokenized[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "                    output_dir=\"./emotions\",\n",
    "                    overwrite_output_dir=True,\n",
    "                    num_train_epochs=10, \n",
    "                    per_device_train_batch_size=2,\n",
    "                    per_device_eval_batch_size=4, \n",
    "                    logging_steps = 500,\n",
    "                    save_steps=500,\n",
    "                    warmup_steps=500,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsorokina/anaconda3/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:742: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 16000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 80000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnastyatrvl\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nastyatrvl/huggingface/runs/sdt7vs0z\" target=\"_blank\">./emotions</a></strong> to <a href=\"https://wandb.ai/nastyatrvl/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80000' max='80000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80000/80000 26:53:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.228400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.859100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.792600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.738500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.714600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.746300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.722000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.715400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>3.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.710500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.239700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.330400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.274800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>3.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.311800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.290800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.244100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.332200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>3.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>3.356600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.359700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>3.357900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>3.293100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>2.885300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.915400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>2.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.917700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>2.966800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.945700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>2.969600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>2.986800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.958800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>2.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>3.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>2.973900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>2.979600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>3.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>3.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>2.602100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>2.603300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>2.602500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>2.600700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>2.681100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>2.634700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>2.649500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>2.641700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>2.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>2.648600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>2.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>2.722300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>2.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>2.650200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>2.697200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>2.685800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>2.353200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>2.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>2.294100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>2.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>2.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>2.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>2.398800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>2.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>2.371500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>2.401300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>2.433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>2.460500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>2.382400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>2.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>2.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>2.429600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>2.087700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>2.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>2.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>2.099200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>2.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>2.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>2.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>2.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>2.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>2.165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>2.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>2.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>2.195600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>2.182100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>2.200700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>2.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>1.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>1.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>1.907300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>1.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>1.966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>1.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>1.953900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>1.961600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>1.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>1.960600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>1.958500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>1.938700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.970700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>1.978600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>1.977100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>1.765900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>1.753900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>1.755600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>1.805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>1.757700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>1.778200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>1.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.799800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>1.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>1.800600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>1.806100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>1.813500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>1.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>1.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>1.801900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>1.796400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>1.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.661200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>1.643400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>1.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>1.657600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>1.651800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>1.660100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>1.646200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>1.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>1.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>1.671300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>1.654900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>1.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>1.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>1.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>1.556700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>1.567400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>1.560400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>1.561700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>1.557300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.568100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75500</td>\n",
       "      <td>1.571800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>1.569900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76500</td>\n",
       "      <td>1.570300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>1.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>1.569100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>1.588700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78500</td>\n",
       "      <td>1.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>1.583500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79500</td>\n",
       "      <td>1.569100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.589100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./emotions/checkpoint-500\n",
      "Configuration saved in ./emotions/checkpoint-500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1000\n",
      "Configuration saved in ./emotions/checkpoint-1000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1500\n",
      "Configuration saved in ./emotions/checkpoint-1500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2000\n",
      "Configuration saved in ./emotions/checkpoint-2000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2500\n",
      "Configuration saved in ./emotions/checkpoint-2500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-3000\n",
      "Configuration saved in ./emotions/checkpoint-3000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-3500\n",
      "Configuration saved in ./emotions/checkpoint-3500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-4000\n",
      "Configuration saved in ./emotions/checkpoint-4000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-4500\n",
      "Configuration saved in ./emotions/checkpoint-4500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-5000\n",
      "Configuration saved in ./emotions/checkpoint-5000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-5500\n",
      "Configuration saved in ./emotions/checkpoint-5500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-5500/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ./emotions/checkpoint-11000\n",
      "Configuration saved in ./emotions/checkpoint-11000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-11500\n",
      "Configuration saved in ./emotions/checkpoint-11500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-12000\n",
      "Configuration saved in ./emotions/checkpoint-12000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-12500\n",
      "Configuration saved in ./emotions/checkpoint-12500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-13000\n",
      "Configuration saved in ./emotions/checkpoint-13000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-13500\n",
      "Configuration saved in ./emotions/checkpoint-13500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-13500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-14000\n",
      "Configuration saved in ./emotions/checkpoint-14000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-14000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-14500\n",
      "Configuration saved in ./emotions/checkpoint-14500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-14500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-15000\n",
      "Configuration saved in ./emotions/checkpoint-15000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-15500\n",
      "Configuration saved in ./emotions/checkpoint-15500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-15500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-16000\n",
      "Configuration saved in ./emotions/checkpoint-16000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-16000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-16500\n",
      "Configuration saved in ./emotions/checkpoint-16500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-16500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-17000\n",
      "Configuration saved in ./emotions/checkpoint-17000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-17500\n",
      "Configuration saved in ./emotions/checkpoint-17500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-17500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-18000\n",
      "Configuration saved in ./emotions/checkpoint-18000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-18000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-18500\n",
      "Configuration saved in ./emotions/checkpoint-18500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-18500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-19000\n",
      "Configuration saved in ./emotions/checkpoint-19000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-19000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-19500\n",
      "Configuration saved in ./emotions/checkpoint-19500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-19500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-20000\n",
      "Configuration saved in ./emotions/checkpoint-20000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-20000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-20500\n",
      "Configuration saved in ./emotions/checkpoint-20500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-20500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-21000\n",
      "Configuration saved in ./emotions/checkpoint-21000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-21000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-21500\n",
      "Configuration saved in ./emotions/checkpoint-21500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-21500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-22000\n",
      "Configuration saved in ./emotions/checkpoint-22000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-22000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-22500\n",
      "Configuration saved in ./emotions/checkpoint-22500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-22500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-23000\n",
      "Configuration saved in ./emotions/checkpoint-23000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-23000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-23500\n",
      "Configuration saved in ./emotions/checkpoint-23500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-23500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-24000\n",
      "Configuration saved in ./emotions/checkpoint-24000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-24000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-24500\n",
      "Configuration saved in ./emotions/checkpoint-24500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-24500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-25000\n",
      "Configuration saved in ./emotions/checkpoint-25000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-25000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-25500\n",
      "Configuration saved in ./emotions/checkpoint-25500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-25500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-26000\n",
      "Configuration saved in ./emotions/checkpoint-26000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-26000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-26500\n",
      "Configuration saved in ./emotions/checkpoint-26500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-26500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-27000\n",
      "Configuration saved in ./emotions/checkpoint-27000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-27000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-27500\n",
      "Configuration saved in ./emotions/checkpoint-27500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-27500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-28000\n",
      "Configuration saved in ./emotions/checkpoint-28000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-28000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ./emotions/checkpoint-30000\n",
      "Configuration saved in ./emotions/checkpoint-30000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-30000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-30500\n",
      "Configuration saved in ./emotions/checkpoint-30500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-30500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-31000\n",
      "Configuration saved in ./emotions/checkpoint-31000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-31000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-31500\n",
      "Configuration saved in ./emotions/checkpoint-31500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-31500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-32000\n",
      "Configuration saved in ./emotions/checkpoint-32000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-32000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-32500\n",
      "Configuration saved in ./emotions/checkpoint-32500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-32500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-33000\n",
      "Configuration saved in ./emotions/checkpoint-33000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-33000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-33500\n",
      "Configuration saved in ./emotions/checkpoint-33500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-33500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-34000\n",
      "Configuration saved in ./emotions/checkpoint-34000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-34000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-34500\n",
      "Configuration saved in ./emotions/checkpoint-34500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-34500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-35000\n",
      "Configuration saved in ./emotions/checkpoint-35000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-35000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-35500\n",
      "Configuration saved in ./emotions/checkpoint-35500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-35500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-36000\n",
      "Configuration saved in ./emotions/checkpoint-36000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-36000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-36500\n",
      "Configuration saved in ./emotions/checkpoint-36500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-36500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-37000\n",
      "Configuration saved in ./emotions/checkpoint-37000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-37000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-37500\n",
      "Configuration saved in ./emotions/checkpoint-37500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-37500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-38000\n",
      "Configuration saved in ./emotions/checkpoint-38000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-38000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-39000\n",
      "Configuration saved in ./emotions/checkpoint-39000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-39000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-39500\n",
      "Configuration saved in ./emotions/checkpoint-39500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-39500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-40000\n",
      "Configuration saved in ./emotions/checkpoint-40000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-40000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-40500\n",
      "Configuration saved in ./emotions/checkpoint-40500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-40500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-41000\n",
      "Configuration saved in ./emotions/checkpoint-41000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-41000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-41500\n",
      "Configuration saved in ./emotions/checkpoint-41500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-41500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-42000\n",
      "Configuration saved in ./emotions/checkpoint-42000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-42000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-42500\n",
      "Configuration saved in ./emotions/checkpoint-42500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-42500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-43000\n",
      "Configuration saved in ./emotions/checkpoint-43000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-43000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-43500\n",
      "Configuration saved in ./emotions/checkpoint-43500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-43500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-44000\n",
      "Configuration saved in ./emotions/checkpoint-44000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-44000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-44500\n",
      "Configuration saved in ./emotions/checkpoint-44500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-44500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-45000\n",
      "Configuration saved in ./emotions/checkpoint-45000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-45000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-45500\n",
      "Configuration saved in ./emotions/checkpoint-45500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-45500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-46000\n",
      "Configuration saved in ./emotions/checkpoint-46000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-46000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-46500\n",
      "Configuration saved in ./emotions/checkpoint-46500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-46500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-47000\n",
      "Configuration saved in ./emotions/checkpoint-47000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-47000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-47500\n",
      "Configuration saved in ./emotions/checkpoint-47500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-47500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-48000\n",
      "Configuration saved in ./emotions/checkpoint-48000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-48000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-48500\n",
      "Configuration saved in ./emotions/checkpoint-48500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-48500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-49000\n",
      "Configuration saved in ./emotions/checkpoint-49000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-49000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-49500\n",
      "Configuration saved in ./emotions/checkpoint-49500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-49500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-50000\n",
      "Configuration saved in ./emotions/checkpoint-50000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-50000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-50500\n",
      "Configuration saved in ./emotions/checkpoint-50500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-50500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-51000\n",
      "Configuration saved in ./emotions/checkpoint-51000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-51000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-51500\n",
      "Configuration saved in ./emotions/checkpoint-51500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-51500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-52000\n",
      "Configuration saved in ./emotions/checkpoint-52000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-52000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-52500\n",
      "Configuration saved in ./emotions/checkpoint-52500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-52500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-53000\n",
      "Configuration saved in ./emotions/checkpoint-53000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-53000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-53500\n",
      "Configuration saved in ./emotions/checkpoint-53500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-53500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-54000\n",
      "Configuration saved in ./emotions/checkpoint-54000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-54000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-54500\n",
      "Configuration saved in ./emotions/checkpoint-54500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-54500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-55000\n",
      "Configuration saved in ./emotions/checkpoint-55000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-55000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-55500\n",
      "Configuration saved in ./emotions/checkpoint-55500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-55500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-56000\n",
      "Configuration saved in ./emotions/checkpoint-56000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-56000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-56500\n",
      "Configuration saved in ./emotions/checkpoint-56500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-56500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-57000\n",
      "Configuration saved in ./emotions/checkpoint-57000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-57000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-57500\n",
      "Configuration saved in ./emotions/checkpoint-57500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-57500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-58000\n",
      "Configuration saved in ./emotions/checkpoint-58000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-58000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-58500\n",
      "Configuration saved in ./emotions/checkpoint-58500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-58500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-59000\n",
      "Configuration saved in ./emotions/checkpoint-59000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-59000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-59500\n",
      "Configuration saved in ./emotions/checkpoint-59500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-59500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-60000\n",
      "Configuration saved in ./emotions/checkpoint-60000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-60000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-60500\n",
      "Configuration saved in ./emotions/checkpoint-60500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-60500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-61000\n",
      "Configuration saved in ./emotions/checkpoint-61000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-61000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-61500\n",
      "Configuration saved in ./emotions/checkpoint-61500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-61500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-62000\n",
      "Configuration saved in ./emotions/checkpoint-62000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-62000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-62500\n",
      "Configuration saved in ./emotions/checkpoint-62500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-62500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-63000\n",
      "Configuration saved in ./emotions/checkpoint-63000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-63000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-63500\n",
      "Configuration saved in ./emotions/checkpoint-63500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-63500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-64000\n",
      "Configuration saved in ./emotions/checkpoint-64000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-64000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-64500\n",
      "Configuration saved in ./emotions/checkpoint-64500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-64500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-65000\n",
      "Configuration saved in ./emotions/checkpoint-65000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-65000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-65500\n",
      "Configuration saved in ./emotions/checkpoint-65500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-65500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-66000\n",
      "Configuration saved in ./emotions/checkpoint-66000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-66000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-66500\n",
      "Configuration saved in ./emotions/checkpoint-66500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-66500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-67000\n",
      "Configuration saved in ./emotions/checkpoint-67000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-67000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-67500\n",
      "Configuration saved in ./emotions/checkpoint-67500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-67500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-68000\n",
      "Configuration saved in ./emotions/checkpoint-68000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-68000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-68500\n",
      "Configuration saved in ./emotions/checkpoint-68500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-68500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-69000\n",
      "Configuration saved in ./emotions/checkpoint-69000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-69000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-69500\n",
      "Configuration saved in ./emotions/checkpoint-69500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-69500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-70000\n",
      "Configuration saved in ./emotions/checkpoint-70000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-70000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-70500\n",
      "Configuration saved in ./emotions/checkpoint-70500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-70500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-71000\n",
      "Configuration saved in ./emotions/checkpoint-71000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-71000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-71500\n",
      "Configuration saved in ./emotions/checkpoint-71500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-71500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-72000\n",
      "Configuration saved in ./emotions/checkpoint-72000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-72000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-72500\n",
      "Configuration saved in ./emotions/checkpoint-72500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-72500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-73000\n",
      "Configuration saved in ./emotions/checkpoint-73000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-73000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-73500\n",
      "Configuration saved in ./emotions/checkpoint-73500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-73500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-74000\n",
      "Configuration saved in ./emotions/checkpoint-74000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-74000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-74500\n",
      "Configuration saved in ./emotions/checkpoint-74500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-74500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-75000\n",
      "Configuration saved in ./emotions/checkpoint-75000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-75000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-75500\n",
      "Configuration saved in ./emotions/checkpoint-75500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-75500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-76000\n",
      "Configuration saved in ./emotions/checkpoint-76000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-76000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-76500\n",
      "Configuration saved in ./emotions/checkpoint-76500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-76500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-77000\n",
      "Configuration saved in ./emotions/checkpoint-77000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-77000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-77500\n",
      "Configuration saved in ./emotions/checkpoint-77500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-77500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-78000\n",
      "Configuration saved in ./emotions/checkpoint-78000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-78000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-78500\n",
      "Configuration saved in ./emotions/checkpoint-78500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-78500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-79000\n",
      "Configuration saved in ./emotions/checkpoint-79000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-79000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-79500\n",
      "Configuration saved in ./emotions/checkpoint-79500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-79500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-80000\n",
      "Configuration saved in ./emotions/checkpoint-80000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-80000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to emotion_fine_tuned/gpt2_full\n",
      "Configuration saved in emotion_fine_tuned/gpt2_full/config.json\n",
      "Model weights saved in emotion_fine_tuned/gpt2_full/pytorch_model.bin\n",
      "tokenizer config file saved in emotion_fine_tuned/gpt2_full/tokenizer_config.json\n",
      "Special tokens file saved in emotion_fine_tuned/gpt2_full/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('emotion_fine_tuned/gpt2_full/tokenizer_config.json',\n",
       " 'emotion_fine_tuned/gpt2_full/special_tokens_map.json',\n",
       " 'emotion_fine_tuned/gpt2_full/vocab.json',\n",
       " 'emotion_fine_tuned/gpt2_full/merges.txt',\n",
       " 'emotion_fine_tuned/gpt2_full/added_tokens.json',\n",
       " 'emotion_fine_tuned/gpt2_full/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    data_collator=data_collator,\n",
    "    train_dataset=emotion_train_dataset)\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"emotion_fine_tuned/gpt2_full\")\n",
    "tokenizer.save_pretrained(\"emotion_fine_tuned/gpt2_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file emotion_fine_tuned/gpt2_full/added_tokens.json. We won't load it.\n",
      "loading file emotion_fine_tuned/gpt2_full/vocab.json\n",
      "loading file emotion_fine_tuned/gpt2_full/merges.txt\n",
      "loading file emotion_fine_tuned/gpt2_full/tokenizer.json\n",
      "loading file None\n",
      "loading file emotion_fine_tuned/gpt2_full/special_tokens_map.json\n",
      "loading file emotion_fine_tuned/gpt2_full/tokenizer_config.json\n",
      "/home/avsorokina/anaconda3/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:742: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "loading configuration file emotion_fine_tuned/gpt2_full/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"emotion_fine_tuned/gpt2_full\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file emotion_fine_tuned/gpt2_full/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at emotion_fine_tuned/gpt2_full.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emotion_fine_tuned/gpt2_full\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"emotion_fine_tuned/gpt2_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_finetune_pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = [\"I am \",\n",
    "             \"I think that\",\n",
    "             \"I like\",\n",
    "             \"I don't like\",\n",
    "             \"I want\",\n",
    "             \"My dream is\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['sadness ', 'joy ', 'love ', 'anger ', 'fear ', 'surprise ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/690674b44bd5b1a7ef81fea02641d3b53827649f92ae54381924832f1edefaac.49a3ba1a12c5b0c12c1f5d39ce0fc262dc3810bdc41be4d875eaf3181375d3f3\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"sadness\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"love\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"fear\",\n",
      "    \"5\": \"surprise\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"fear\": 4,\n",
      "    \"joy\": 1,\n",
      "    \"love\": 2,\n",
      "    \"sadness\": 0,\n",
      "    \"surprise\": 5\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/690674b44bd5b1a7ef81fea02641d3b53827649f92ae54381924832f1edefaac.49a3ba1a12c5b0c12c1f5d39ce0fc262dc3810bdc41be4d875eaf3181375d3f3\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"sadness\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"love\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"fear\",\n",
      "    \"5\": \"surprise\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"fear\": 4,\n",
      "    \"joy\": 1,\n",
      "    \"love\": 2,\n",
      "    \"sadness\": 0,\n",
      "    \"surprise\": 5\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/pytorch_model.bin from cache at /home/avsorokina/.cache/huggingface/transformers/659b731e8f774ee09297241f4f017897a918d684dbc8705945b60d037166cbd2.9f784735acea1cb2b556df79277f0107f362c25420753d20abb71187c2780b69\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/690674b44bd5b1a7ef81fea02641d3b53827649f92ae54381924832f1edefaac.49a3ba1a12c5b0c12c1f5d39ce0fc262dc3810bdc41be4d875eaf3181375d3f3\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"sadness\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"love\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"fear\",\n",
      "    \"5\": \"surprise\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"fear\": 4,\n",
      "    \"joy\": 1,\n",
      "    \"love\": 2,\n",
      "    \"sadness\": 0,\n",
      "    \"surprise\": 5\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/vocab.txt from cache at /home/avsorokina/.cache/huggingface/transformers/177e130d3461c7fd67abb489165edc09ae35889a9de9c200ed8994daeab51c2b.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/special_tokens_map.json from cache at /home/avsorokina/.cache/huggingface/transformers/c93be830da9a99006a4c8704e67d6a5ae20cd830e5d15acec4a9a538da90fe7e.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/tokenizer_config.json from cache at /home/avsorokina/.cache/huggingface/transformers/97ad2ff7c0f6b5a1d2b1c925a1cf3e710d332d663c054d3fcef0d517fbeca73e.94d21ec8260a5d55996d2e17c44b67294f61b49b170de6140f30e7c36515736b\n",
      "loading configuration file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/690674b44bd5b1a7ef81fea02641d3b53827649f92ae54381924832f1edefaac.49a3ba1a12c5b0c12c1f5d39ce0fc262dc3810bdc41be4d875eaf3181375d3f3\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"sadness\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"love\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"fear\",\n",
      "    \"5\": \"surprise\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"fear\": 4,\n",
      "    \"joy\": 1,\n",
      "    \"love\": 2,\n",
      "    \"sadness\": 0,\n",
      "    \"surprise\": 5\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/690674b44bd5b1a7ef81fea02641d3b53827649f92ae54381924832f1edefaac.49a3ba1a12c5b0c12c1f5d39ce0fc262dc3810bdc41be4d875eaf3181375d3f3\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"sadness\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"love\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"fear\",\n",
      "    \"5\": \"surprise\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"fear\": 4,\n",
      "    \"joy\": 1,\n",
      "    \"love\": 2,\n",
      "    \"sadness\": 0,\n",
      "    \"surprise\": 5\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\",model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/9c70675f5e9090fae783ea1880a8e785e68bda247a0ae8fb5cd1bbdc86cbc4c7.cd7e8a4fe6807ed49afe99d5a84290c6c94c4855bef92225d127edbbf327a2c9\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"arpanghoshal/EmoRoBERTa\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"admiration\",\n",
      "    \"1\": \"amusement\",\n",
      "    \"2\": \"anger\",\n",
      "    \"3\": \"annoyance\",\n",
      "    \"4\": \"approval\",\n",
      "    \"5\": \"caring\",\n",
      "    \"6\": \"confusion\",\n",
      "    \"7\": \"curiosity\",\n",
      "    \"8\": \"desire\",\n",
      "    \"9\": \"disappointment\",\n",
      "    \"10\": \"disapproval\",\n",
      "    \"11\": \"disgust\",\n",
      "    \"12\": \"embarrassment\",\n",
      "    \"13\": \"excitement\",\n",
      "    \"14\": \"fear\",\n",
      "    \"15\": \"gratitude\",\n",
      "    \"16\": \"grief\",\n",
      "    \"17\": \"joy\",\n",
      "    \"18\": \"love\",\n",
      "    \"19\": \"nervousness\",\n",
      "    \"20\": \"optimism\",\n",
      "    \"21\": \"pride\",\n",
      "    \"22\": \"realization\",\n",
      "    \"23\": \"relief\",\n",
      "    \"24\": \"remorse\",\n",
      "    \"25\": \"sadness\",\n",
      "    \"26\": \"surprise\",\n",
      "    \"27\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"admiration\": 0,\n",
      "    \"amusement\": 1,\n",
      "    \"anger\": 2,\n",
      "    \"annoyance\": 3,\n",
      "    \"approval\": 4,\n",
      "    \"caring\": 5,\n",
      "    \"confusion\": 6,\n",
      "    \"curiosity\": 7,\n",
      "    \"desire\": 8,\n",
      "    \"disappointment\": 9,\n",
      "    \"disapproval\": 10,\n",
      "    \"disgust\": 11,\n",
      "    \"embarrassment\": 12,\n",
      "    \"excitement\": 13,\n",
      "    \"fear\": 14,\n",
      "    \"gratitude\": 15,\n",
      "    \"grief\": 16,\n",
      "    \"joy\": 17,\n",
      "    \"love\": 18,\n",
      "    \"nervousness\": 19,\n",
      "    \"neutral\": 27,\n",
      "    \"optimism\": 20,\n",
      "    \"pride\": 21,\n",
      "    \"realization\": 22,\n",
      "    \"relief\": 23,\n",
      "    \"remorse\": 24,\n",
      "    \"sadness\": 25,\n",
      "    \"surprise\": 26\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/9c70675f5e9090fae783ea1880a8e785e68bda247a0ae8fb5cd1bbdc86cbc4c7.cd7e8a4fe6807ed49afe99d5a84290c6c94c4855bef92225d127edbbf327a2c9\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"arpanghoshal/EmoRoBERTa\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"admiration\",\n",
      "    \"1\": \"amusement\",\n",
      "    \"2\": \"anger\",\n",
      "    \"3\": \"annoyance\",\n",
      "    \"4\": \"approval\",\n",
      "    \"5\": \"caring\",\n",
      "    \"6\": \"confusion\",\n",
      "    \"7\": \"curiosity\",\n",
      "    \"8\": \"desire\",\n",
      "    \"9\": \"disappointment\",\n",
      "    \"10\": \"disapproval\",\n",
      "    \"11\": \"disgust\",\n",
      "    \"12\": \"embarrassment\",\n",
      "    \"13\": \"excitement\",\n",
      "    \"14\": \"fear\",\n",
      "    \"15\": \"gratitude\",\n",
      "    \"16\": \"grief\",\n",
      "    \"17\": \"joy\",\n",
      "    \"18\": \"love\",\n",
      "    \"19\": \"nervousness\",\n",
      "    \"20\": \"optimism\",\n",
      "    \"21\": \"pride\",\n",
      "    \"22\": \"realization\",\n",
      "    \"23\": \"relief\",\n",
      "    \"24\": \"remorse\",\n",
      "    \"25\": \"sadness\",\n",
      "    \"26\": \"surprise\",\n",
      "    \"27\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"admiration\": 0,\n",
      "    \"amusement\": 1,\n",
      "    \"anger\": 2,\n",
      "    \"annoyance\": 3,\n",
      "    \"approval\": 4,\n",
      "    \"caring\": 5,\n",
      "    \"confusion\": 6,\n",
      "    \"curiosity\": 7,\n",
      "    \"desire\": 8,\n",
      "    \"disappointment\": 9,\n",
      "    \"disapproval\": 10,\n",
      "    \"disgust\": 11,\n",
      "    \"embarrassment\": 12,\n",
      "    \"excitement\": 13,\n",
      "    \"fear\": 14,\n",
      "    \"gratitude\": 15,\n",
      "    \"grief\": 16,\n",
      "    \"joy\": 17,\n",
      "    \"love\": 18,\n",
      "    \"nervousness\": 19,\n",
      "    \"neutral\": 27,\n",
      "    \"optimism\": 20,\n",
      "    \"pride\": 21,\n",
      "    \"realization\": 22,\n",
      "    \"relief\": 23,\n",
      "    \"remorse\": 24,\n",
      "    \"sadness\": 25,\n",
      "    \"surprise\": 26\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "404 Client Error: Not Found for url: https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/pytorch_model.bin\n",
      "loading configuration file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/9c70675f5e9090fae783ea1880a8e785e68bda247a0ae8fb5cd1bbdc86cbc4c7.cd7e8a4fe6807ed49afe99d5a84290c6c94c4855bef92225d127edbbf327a2c9\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"arpanghoshal/EmoRoBERTa\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"admiration\",\n",
      "    \"1\": \"amusement\",\n",
      "    \"2\": \"anger\",\n",
      "    \"3\": \"annoyance\",\n",
      "    \"4\": \"approval\",\n",
      "    \"5\": \"caring\",\n",
      "    \"6\": \"confusion\",\n",
      "    \"7\": \"curiosity\",\n",
      "    \"8\": \"desire\",\n",
      "    \"9\": \"disappointment\",\n",
      "    \"10\": \"disapproval\",\n",
      "    \"11\": \"disgust\",\n",
      "    \"12\": \"embarrassment\",\n",
      "    \"13\": \"excitement\",\n",
      "    \"14\": \"fear\",\n",
      "    \"15\": \"gratitude\",\n",
      "    \"16\": \"grief\",\n",
      "    \"17\": \"joy\",\n",
      "    \"18\": \"love\",\n",
      "    \"19\": \"nervousness\",\n",
      "    \"20\": \"optimism\",\n",
      "    \"21\": \"pride\",\n",
      "    \"22\": \"realization\",\n",
      "    \"23\": \"relief\",\n",
      "    \"24\": \"remorse\",\n",
      "    \"25\": \"sadness\",\n",
      "    \"26\": \"surprise\",\n",
      "    \"27\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"admiration\": 0,\n",
      "    \"amusement\": 1,\n",
      "    \"anger\": 2,\n",
      "    \"annoyance\": 3,\n",
      "    \"approval\": 4,\n",
      "    \"caring\": 5,\n",
      "    \"confusion\": 6,\n",
      "    \"curiosity\": 7,\n",
      "    \"desire\": 8,\n",
      "    \"disappointment\": 9,\n",
      "    \"disapproval\": 10,\n",
      "    \"disgust\": 11,\n",
      "    \"embarrassment\": 12,\n",
      "    \"excitement\": 13,\n",
      "    \"fear\": 14,\n",
      "    \"gratitude\": 15,\n",
      "    \"grief\": 16,\n",
      "    \"joy\": 17,\n",
      "    \"love\": 18,\n",
      "    \"nervousness\": 19,\n",
      "    \"neutral\": 27,\n",
      "    \"optimism\": 20,\n",
      "    \"pride\": 21,\n",
      "    \"realization\": 22,\n",
      "    \"relief\": 23,\n",
      "    \"remorse\": 24,\n",
      "    \"sadness\": 25,\n",
      "    \"surprise\": 26\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/tf_model.h5 from cache at /home/avsorokina/.cache/huggingface/transformers/f68796b9a7d2cdf455e3febdeefe49f058a868a969d1cede7f56faa1a3d7518e.2733e70f07b0a7342a8e21afd7812f3f44b5e7fdb51e7c0b9634da16316708be.h5\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/9c70675f5e9090fae783ea1880a8e785e68bda247a0ae8fb5cd1bbdc86cbc4c7.cd7e8a4fe6807ed49afe99d5a84290c6c94c4855bef92225d127edbbf327a2c9\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"arpanghoshal/EmoRoBERTa\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"admiration\",\n",
      "    \"1\": \"amusement\",\n",
      "    \"2\": \"anger\",\n",
      "    \"3\": \"annoyance\",\n",
      "    \"4\": \"approval\",\n",
      "    \"5\": \"caring\",\n",
      "    \"6\": \"confusion\",\n",
      "    \"7\": \"curiosity\",\n",
      "    \"8\": \"desire\",\n",
      "    \"9\": \"disappointment\",\n",
      "    \"10\": \"disapproval\",\n",
      "    \"11\": \"disgust\",\n",
      "    \"12\": \"embarrassment\",\n",
      "    \"13\": \"excitement\",\n",
      "    \"14\": \"fear\",\n",
      "    \"15\": \"gratitude\",\n",
      "    \"16\": \"grief\",\n",
      "    \"17\": \"joy\",\n",
      "    \"18\": \"love\",\n",
      "    \"19\": \"nervousness\",\n",
      "    \"20\": \"optimism\",\n",
      "    \"21\": \"pride\",\n",
      "    \"22\": \"realization\",\n",
      "    \"23\": \"relief\",\n",
      "    \"24\": \"remorse\",\n",
      "    \"25\": \"sadness\",\n",
      "    \"26\": \"surprise\",\n",
      "    \"27\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"admiration\": 0,\n",
      "    \"amusement\": 1,\n",
      "    \"anger\": 2,\n",
      "    \"annoyance\": 3,\n",
      "    \"approval\": 4,\n",
      "    \"caring\": 5,\n",
      "    \"confusion\": 6,\n",
      "    \"curiosity\": 7,\n",
      "    \"desire\": 8,\n",
      "    \"disappointment\": 9,\n",
      "    \"disapproval\": 10,\n",
      "    \"disgust\": 11,\n",
      "    \"embarrassment\": 12,\n",
      "    \"excitement\": 13,\n",
      "    \"fear\": 14,\n",
      "    \"gratitude\": 15,\n",
      "    \"grief\": 16,\n",
      "    \"joy\": 17,\n",
      "    \"love\": 18,\n",
      "    \"nervousness\": 19,\n",
      "    \"neutral\": 27,\n",
      "    \"optimism\": 20,\n",
      "    \"pride\": 21,\n",
      "    \"realization\": 22,\n",
      "    \"relief\": 23,\n",
      "    \"remorse\": 24,\n",
      "    \"sadness\": 25,\n",
      "    \"surprise\": 26\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/vocab.json from cache at /home/avsorokina/.cache/huggingface/transformers/9fc13941fc3e58a1e5ab004a0ba6e67c4183f28c6c65a4ed36022aa8250cb5c6.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/merges.txt from cache at /home/avsorokina/.cache/huggingface/transformers/6cd6b6a7ab1dffe8a9a799e341110a5a112a263575579e7cc4ca869339a688bc.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/special_tokens_map.json from cache at /home/avsorokina/.cache/huggingface/transformers/97210fb0140c29de6b11c6c1046416ca9ae11854125e2956252a432062ba1a8d.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/tokenizer_config.json from cache at /home/avsorokina/.cache/huggingface/transformers/eba837b4a29a94c70054b23ef1c20f9d6c4d68722765284b960e7fa634d032a7.024cc07195c0ba0b51d4f80061c6115996ff26233f3d04788855b23cdf13fbd5\n",
      "loading configuration file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/9c70675f5e9090fae783ea1880a8e785e68bda247a0ae8fb5cd1bbdc86cbc4c7.cd7e8a4fe6807ed49afe99d5a84290c6c94c4855bef92225d127edbbf327a2c9\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"arpanghoshal/EmoRoBERTa\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"admiration\",\n",
      "    \"1\": \"amusement\",\n",
      "    \"2\": \"anger\",\n",
      "    \"3\": \"annoyance\",\n",
      "    \"4\": \"approval\",\n",
      "    \"5\": \"caring\",\n",
      "    \"6\": \"confusion\",\n",
      "    \"7\": \"curiosity\",\n",
      "    \"8\": \"desire\",\n",
      "    \"9\": \"disappointment\",\n",
      "    \"10\": \"disapproval\",\n",
      "    \"11\": \"disgust\",\n",
      "    \"12\": \"embarrassment\",\n",
      "    \"13\": \"excitement\",\n",
      "    \"14\": \"fear\",\n",
      "    \"15\": \"gratitude\",\n",
      "    \"16\": \"grief\",\n",
      "    \"17\": \"joy\",\n",
      "    \"18\": \"love\",\n",
      "    \"19\": \"nervousness\",\n",
      "    \"20\": \"optimism\",\n",
      "    \"21\": \"pride\",\n",
      "    \"22\": \"realization\",\n",
      "    \"23\": \"relief\",\n",
      "    \"24\": \"remorse\",\n",
      "    \"25\": \"sadness\",\n",
      "    \"26\": \"surprise\",\n",
      "    \"27\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"admiration\": 0,\n",
      "    \"amusement\": 1,\n",
      "    \"anger\": 2,\n",
      "    \"annoyance\": 3,\n",
      "    \"approval\": 4,\n",
      "    \"caring\": 5,\n",
      "    \"confusion\": 6,\n",
      "    \"curiosity\": 7,\n",
      "    \"desire\": 8,\n",
      "    \"disappointment\": 9,\n",
      "    \"disapproval\": 10,\n",
      "    \"disgust\": 11,\n",
      "    \"embarrassment\": 12,\n",
      "    \"excitement\": 13,\n",
      "    \"fear\": 14,\n",
      "    \"gratitude\": 15,\n",
      "    \"grief\": 16,\n",
      "    \"joy\": 17,\n",
      "    \"love\": 18,\n",
      "    \"nervousness\": 19,\n",
      "    \"neutral\": 27,\n",
      "    \"optimism\": 20,\n",
      "    \"pride\": 21,\n",
      "    \"realization\": 22,\n",
      "    \"relief\": 23,\n",
      "    \"remorse\": 24,\n",
      "    \"sadness\": 25,\n",
      "    \"surprise\": 26\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/9c70675f5e9090fae783ea1880a8e785e68bda247a0ae8fb5cd1bbdc86cbc4c7.cd7e8a4fe6807ed49afe99d5a84290c6c94c4855bef92225d127edbbf327a2c9\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"arpanghoshal/EmoRoBERTa\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"admiration\",\n",
      "    \"1\": \"amusement\",\n",
      "    \"2\": \"anger\",\n",
      "    \"3\": \"annoyance\",\n",
      "    \"4\": \"approval\",\n",
      "    \"5\": \"caring\",\n",
      "    \"6\": \"confusion\",\n",
      "    \"7\": \"curiosity\",\n",
      "    \"8\": \"desire\",\n",
      "    \"9\": \"disappointment\",\n",
      "    \"10\": \"disapproval\",\n",
      "    \"11\": \"disgust\",\n",
      "    \"12\": \"embarrassment\",\n",
      "    \"13\": \"excitement\",\n",
      "    \"14\": \"fear\",\n",
      "    \"15\": \"gratitude\",\n",
      "    \"16\": \"grief\",\n",
      "    \"17\": \"joy\",\n",
      "    \"18\": \"love\",\n",
      "    \"19\": \"nervousness\",\n",
      "    \"20\": \"optimism\",\n",
      "    \"21\": \"pride\",\n",
      "    \"22\": \"realization\",\n",
      "    \"23\": \"relief\",\n",
      "    \"24\": \"remorse\",\n",
      "    \"25\": \"sadness\",\n",
      "    \"26\": \"surprise\",\n",
      "    \"27\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"admiration\": 0,\n",
      "    \"amusement\": 1,\n",
      "    \"anger\": 2,\n",
      "    \"annoyance\": 3,\n",
      "    \"approval\": 4,\n",
      "    \"caring\": 5,\n",
      "    \"confusion\": 6,\n",
      "    \"curiosity\": 7,\n",
      "    \"desire\": 8,\n",
      "    \"disappointment\": 9,\n",
      "    \"disapproval\": 10,\n",
      "    \"disgust\": 11,\n",
      "    \"embarrassment\": 12,\n",
      "    \"excitement\": 13,\n",
      "    \"fear\": 14,\n",
      "    \"gratitude\": 15,\n",
      "    \"grief\": 16,\n",
      "    \"joy\": 17,\n",
      "    \"love\": 18,\n",
      "    \"nervousness\": 19,\n",
      "    \"neutral\": 27,\n",
      "    \"optimism\": 20,\n",
      "    \"pride\": 21,\n",
      "    \"realization\": 22,\n",
      "    \"relief\": 23,\n",
      "    \"remorse\": 24,\n",
      "    \"sadness\": 25,\n",
      "    \"surprise\": 26\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier2 = pipeline(\"text-classification\",model='arpanghoshal/EmoRoBERTa', return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadness  \n",
      "\n",
      "\n",
      "I am ive been feeling so depressed lately that i want to quit my job and cross the finish line somewhere in between episodes of housewife drama or sitcom limbo where everything just feels resolved and thrown into place like a thrown jigsaw which \n",
      "\n",
      " {'label': 'sadness', 'score': 0.999117910861969} \n",
      "\n",
      " {'label': 'disappointment', 'score': 0.7120047807693481}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that i shouldnt have left this place feeling humiliated and alone so i did what every mother does when she has a child who is born without her or no one but the thought of leaving was making me feel stressed out worried upset \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9989664554595947} \n",
      "\n",
      " {'label': 'disappointment', 'score': 0.7229012250900269}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like i was on top of my game and i just kind of lost myself feeling unhappy about it all day too worried that i wasn t doing enough to keep up with other girls on etsy or what have you and then got really \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9989744424819946} \n",
      "\n",
      " {'label': 'disappointment', 'score': 0.4550275206565857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like the idea of a comeback even when it s just for an hour before you feel totally drained and exhausted and you realize that you can t just let go without making any real progress towards your goal which is to finish all \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9989689588546753} \n",
      "\n",
      " {'label': 'disapproval', 'score': 0.9881496429443359}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I want to do something cause i feel so listless and depressed and at such a young age what can i do to really change that pattern which is the cause of my current problems hopefully soon i will come across an resolution but for now \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9988865256309509} \n",
      "\n",
      " {'label': 'optimism', 'score': 0.5241937041282654}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is of her getting married but i woke up feeling heartbroken and disappointed because my husband didnt offer to let me have the baby i wanted but he did give us the darn wedding ring i had been desperately hoping for and it was \n",
      "\n",
      " {'label': 'sadness', 'score': 0.999087929725647} \n",
      "\n",
      " {'label': 'disappointment', 'score': 0.3228181302547455}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "joy  \n",
      "\n",
      "\n",
      "I am ive been feeling quite productive lately so i thought id share two blogs that ive written each time around my brain for fun reasons not mine but it sure helps to keep me entertained at school and whenever im in the studio with other students \n",
      "\n",
      " {'label': 'joy', 'score': 0.998855471611023} \n",
      "\n",
      " {'label': 'joy', 'score': 0.9835203289985657}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that is how it must feel to be popular and successful in today s society although sometimes we may not realize it until long after our society s success story begins oh yes it happens but i m sure there are some who still have questions about \n",
      "\n",
      " {'label': 'joy', 'score': 0.9988934397697449} \n",
      "\n",
      " {'label': 'realization', 'score': 0.9954924583435059}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like to listen and feel the wind blow through me i know its not pleasant but i know it will give you a major headache every time you open your eyes or walk out of your window just because you are afraid of something bad happening to you \n",
      "\n",
      " {'label': 'joy', 'score': 0.9987170696258545} \n",
      "\n",
      " {'label': 'approval', 'score': 0.5180113911628723}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like the cold and certainly feel less lethargic than many other people i know but for some reason im not really eating well most of the time which is ludicrous so i guess ill just have to deal with that now before we go \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9989835619926453} \n",
      "\n",
      " {'label': 'disapproval', 'score': 0.9801872372627258}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I want to feel like im not special but that maybe in some ways i am just a little bit underrated because of my musical tastes haha so many have asked me for music for their hit single and i can relate with them both way as an artist \n",
      "\n",
      " {'label': 'joy', 'score': 0.9987776875495911} \n",
      "\n",
      " {'label': 'amusement', 'score': 0.8602355718612671}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is that she would feel so divine to share it with me but i dont believe that she will because she has no desire for me and doesnt want any contact with anyone outside of her small circle in the real life world without my express written \n",
      "\n",
      " {'label': 'joy', 'score': 0.9988136291503906} \n",
      "\n",
      " {'label': 'desire', 'score': 0.4756956398487091}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "love  \n",
      "\n",
      "\n",
      "I am ive been feeling kind of naughty lately so i thought id do something different and easier to giggle around in my sand salad if you please but im going for a really big ol stomach and no bbq since im not feeling well \n",
      "\n",
      " {'label': 'love', 'score': 0.9923902153968811} \n",
      "\n",
      " {'label': 'realization', 'score': 0.488015741109848}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that is how christians who feel the most repressed about homosexuality are supposed to be when they are repentant and penance for their sins against christianity christians have been taught to forgive all human frailties in favor of \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9986371397972107} \n",
      "\n",
      " {'label': 'realization', 'score': 0.9833245277404785}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like the feeling of a hot bath or spa treatment plus it smells really lovely and soothing as well so im not complaining too much about that here it comes gaga which is an all time favourite of mine coz i just love it cos i \n",
      "\n",
      " {'label': 'love', 'score': 0.9950496554374695} \n",
      "\n",
      " {'label': 'love', 'score': 0.8765031695365906}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like the word rich or it could be anything but i feel that people shouldn t pay a little bit for someone to have that kind of life without knowing theyre getting robbed by somebody else s greed and lackadaisies pining \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9951752424240112} \n",
      "\n",
      " {'label': 'disapproval', 'score': 0.9069553017616272}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I want to be loved and cherished long term i feel like i m being asked to do something that is not socially acceptable or even remotelyable to others people of my sexual persuasion right now so i have no choice but either way this conversation has its \n",
      "\n",
      " {'label': 'joy', 'score': 0.998472273349762} \n",
      "\n",
      " {'label': 'love', 'score': 0.9717814326286316}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is of flowers and precious things that can be found in the depths beneath our feet but what if it was only for a moment or two before you woke up feeling horny hungry thirsty etc because hey baby how about that honeycomb you got me \n",
      "\n",
      " {'label': 'love', 'score': 0.9937087297439575} \n",
      "\n",
      " {'label': 'neutral', 'score': 0.3204132616519928}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "anger  \n",
      "\n",
      "\n",
      "I am ive been feeling a bit grumpy for some reason but i just cant seem to keep up with other bloggers in the area of blogging and thats why i decided today not to post entries into this blogosphere mainnetherland forum as \n",
      "\n",
      " {'label': 'anger', 'score': 0.9982079267501831} \n",
      "\n",
      " {'label': 'realization', 'score': 0.6486588716506958}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that theres a good chance i might feel resentful or whatever if its in my own home town and i dont know what to do with myself and thats too bad because im here right now without power and all i have left is some \n",
      "\n",
      " {'label': 'anger', 'score': 0.998036801815033} \n",
      "\n",
      " {'label': 'realization', 'score': 0.3297750949859619}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like i was feeling rebellious which is usually when im prepping for a midterm or major in something that is supposed to be about teaching and the like so everybody gathers around me and starts yelling at each other not knowing what im suppose to say unless \n",
      "\n",
      " {'label': 'anger', 'score': 0.9977217316627502} \n",
      "\n",
      " {'label': 'realization', 'score': 0.39540067315101624}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like the way i feel from a bad actor or an action figure in my movie or television series especially when there are violent scenes and music in it but i think actors should be respected even if they make up some of them instead o \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9975138902664185} \n",
      "\n",
      " {'label': 'disapproval', 'score': 0.98915696144104}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I wanton stealing someone elses sewing machine or attempting to steal a saw from another person in such an act which is so horrible it would be reckless reckless and extremely dangerous for anyone but me i feel like this wouldnt have happened if the perpetrator \n",
      "\n",
      " {'label': 'anger', 'score': 0.9437554478645325} \n",
      "\n",
      " {'label': 'fear', 'score': 0.8180891871452332}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is so violent i feel my brain damaged are getting worst for ever what do you think of the cyber warriors while the general environment around it is friendly and pleasant at best but full blown in cyberspace with hostile intentions as well as paranoia \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9969812035560608} \n",
      "\n",
      " {'label': 'sadness', 'score': 0.6379262804985046}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "fear  \n",
      "\n",
      "\n",
      "I am ive been feeling restless in my career because i feel like im leaving behind a pretty good chunk of the people who were there when we landed at york and joined forces with other internetshire based companies to create this wonderfulservice \n",
      "\n",
      " {'label': 'fear', 'score': 0.9975149631500244} \n",
      "\n",
      " {'label': 'approval', 'score': 0.783829391002655}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that i should go to the church service instead of feeling frightened because im not in it alone and its really not worth doing since there are so many other reasons why not just be a part time missionary with me but seriously still wanting something \n",
      "\n",
      " {'label': 'fear', 'score': 0.9975148439407349} \n",
      "\n",
      " {'label': 'desire', 'score': 0.424512654542923}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like i said earlier this year im feeling pretty intimidated by the amount of people that seem to be in groups and at work who seem sincere but have no clue how or why they are doing it so there is always a risk if they dont \n",
      "\n",
      " {'label': 'fear', 'score': 0.9972694516181946} \n",
      "\n",
      " {'label': 'embarrassment', 'score': 0.6422436833381653}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like to do it when i feel threatened by another human being even though that person is different from me in some ways and has obviously never been before i was a child i have tortured people for no reason thats why i am tortured \n",
      "\n",
      " {'label': 'fear', 'score': 0.9975201487541199} \n",
      "\n",
      " {'label': 'disapproval', 'score': 0.7030242681503296}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I want to feel frightened of them and afraid they can hurt me or worse i will just be tormented for the rest of my life in this hell like place where i belong but only because of their own selfishness so i am helpless to \n",
      "\n",
      " {'label': 'fear', 'score': 0.9977577328681946} \n",
      "\n",
      " {'label': 'fear', 'score': 0.9928701519966125}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is of her having a baby but when i wake up feeling shaky and weak she has this strange dream where she wants me to be so she can take away my anxiety and make me feel happy again the only thing that matters is my \n",
      "\n",
      " {'label': 'fear', 'score': 0.9961187839508057} \n",
      "\n",
      " {'label': 'joy', 'score': 0.6353330612182617}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "surprise  \n",
      "\n",
      "\n",
      "I am ive been feeling really overwhelmed with my life lately i realize that this is where godly men have been trying so hard to do for us and thats why im here in the first place we are all having challenges and challenges like these \n",
      "\n",
      " {'label': 'surprise', 'score': 0.7665645480155945} \n",
      "\n",
      " {'label': 'realization', 'score': 0.9964901804924011}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that theres nothing inherently wrong with feeling overwhelmed and at other times sad or scared because of illness i dont usually have many friends in my life at least not for a good reason often just because i dont want to be alone in it \n",
      "\n",
      " {'label': 'surprise', 'score': 0.7328115105628967} \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9849549531936646}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like i am in a field trip and i feel so strange with it all on my plate without anybody noticing me or even listening to the story and suddenly i am not even enthralled by everything that is happening around us everyday except for \n",
      "\n",
      " {'label': 'fear', 'score': 0.6483353972434998} \n",
      "\n",
      " {'label': 'realization', 'score': 0.6929041743278503}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like the way i feel when i am shocked and stunned by something or other story that has been going on for months and days and i am reminded of just how sick these people are all must be of the world after so much \n",
      "\n",
      " {'label': 'surprise', 'score': 0.9915627241134644} \n",
      "\n",
      " {'label': 'disapproval', 'score': 0.8262115716934204}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I wanton mayhem i feel a little overwhelmed by it all but im not taking it easy any more this is taking it toll on my already shaky confidence in the abilities of both her and myself to handle it and hopefully get through it without making \n",
      "\n",
      " {'label': 'fear', 'score': 0.6285878419876099} \n",
      "\n",
      " {'label': 'optimism', 'score': 0.7132954001426697}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is that i would be able to feel it and im shocked that i didnt just create this dream but all i remember was my waking up moment with the distinct feeling of being disturbed and its still something very strange for me to say the \n",
      "\n",
      " {'label': 'surprise', 'score': 0.9919697642326355} \n",
      "\n",
      " {'label': 'surprise', 'score': 0.9565743803977966}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for emotion in emotions:\n",
    "    print(emotion, 2*\"\\n\")\n",
    "    for prompt in test_prompts:\n",
    "        res = gpt2_finetune_pipe(text_inputs=emotion+prompt, \n",
    "                          top_k = 50,\n",
    "                          top_p = 0.95,\n",
    "                          no_repeat_ngram_size = 3,  \n",
    "                          repetition_penalty=1.2,\n",
    "                          max_length = 50,\n",
    "                          temperature = 0.7)\n",
    "        res = res[0]['generated_text'].split(' ', 1)[1] #remove first token indicating emotion before classification\n",
    "        prediction1 = classifier(res)\n",
    "        prediction2 = classifier2(res)\n",
    "        prediction1 = sorted(prediction1[0], key=lambda d: d['score'], reverse = True) \n",
    "        prediction2 = sorted(prediction2[0], key=lambda d: d['score'], reverse = True) \n",
    "        print(res, 2*\"\\n\", prediction1[0], 2*\"\\n\", prediction2[0])\n",
    "        print(100*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
