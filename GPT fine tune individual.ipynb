{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (AutoTokenizer, GPT2Tokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, AutoModelForCausalLM, GPT2LMHeadModel, AutoModelWithLMHead,\n",
    "                         DataCollatorForLanguageModeling, pipeline)\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data (Emotion dataset by Twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset emotion (/home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ad8a57554148779ce22b44f8b553fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion_dataset = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-3315adf707f1f657.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-4045f2553a29b14d.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-a4014524468efda4.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-67a76582b0169275.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-7d3e782fefa500ca.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-2dd30d978fbd2391.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-3bb2dddea9d0bc0a.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-79da8b4e9ae47fa3.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-638bfefd81fe323a.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-d948686578d4c1f9.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-83e3f45c13fdb994.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-880362acf03d3f3a.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-399e110512ca95e7.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-09b2ec9106c90911.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-3ac990840e4a0feb.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-744b21b520caaeea.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-053a9e7ab984665b.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-6f66985c785a133c.arrow\n"
     ]
    }
   ],
   "source": [
    "# prepare individual datasets for every emotion\n",
    "\n",
    "emotion_dataset_sadness = emotion_dataset.filter(lambda record: record['label']==0)\n",
    "emotion_dataset_joy = emotion_dataset.filter(lambda record: record['label']==1)\n",
    "emotion_dataset_love = emotion_dataset.filter(lambda record: record['label']==2)\n",
    "emotion_dataset_anger = emotion_dataset.filter(lambda record: record['label']==3)\n",
    "emotion_dataset_fear = emotion_dataset.filter(lambda record: record['label']==4)\n",
    "emotion_dataset_surprise = emotion_dataset.filter(lambda record: record['label']==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tolenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(record):\n",
    "    return tokenizer(record[\"text\"], padding = \"max_length\", truncation = True, max_length = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-2cb30565284d9a62.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-15b4bd57b7dcf299.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39be993c26c4b6c8e5ff111772be237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/581 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-76f09b1eb73890f1.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-67881207f4809dae.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-867718b4290685d2.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-92070843494168e5.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-9cacb76c255a0ddf.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-f367f83d84f5948c.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-171363ba791493f5.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-90a1a928b01723c1.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-faaf8cf3729c2593.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-e9c7fe46afc9fcb4.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-ab46ffc15940a77a.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-a01c6ca93f56267f.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-4af8d890a30a8800.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-45f9ff1188d44162.arrow\n",
      "Loading cached processed dataset at /home/avsorokina/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705/cache-c92c719868c547a8.arrow\n"
     ]
    }
   ],
   "source": [
    "sadness_tokenized = emotion_dataset_sadness.map(tokenize_func)\n",
    "joy_tokenized = emotion_dataset_joy.map(tokenize_func)\n",
    "love_tokenized = emotion_dataset_love.map(tokenize_func)\n",
    "anger_tokenized = emotion_dataset_anger.map(tokenize_func)\n",
    "fear_tokenized = emotion_dataset_fear.map(tokenize_func)\n",
    "surprise_tokenized = emotion_dataset_surprise.map(tokenize_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove useless columns + rename + change format\n",
    "\n",
    "sadness_tokenized = sadness_tokenized.remove_columns(['text']).rename_column('label', 'labels').with_format('torch')\n",
    "joy_tokenized = joy_tokenized.remove_columns(['text']).rename_column('label', 'labels').with_format('torch')\n",
    "love_tokenized = love_tokenized.remove_columns(['text']).rename_column('label', 'labels').with_format('torch')\n",
    "anger_tokenized = anger_tokenized.remove_columns(['text']).rename_column('label', 'labels').with_format('torch')\n",
    "fear_tokenized = fear_tokenized.remove_columns(['text']).rename_column('label', 'labels').with_format('torch')\n",
    "surprise_tokenized = surprise_tokenized.remove_columns(['text']).rename_column('label', 'labels').with_format('torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadness_train_dataset, sadness_eval_dataset = sadness_tokenized[\"train\"], sadness_tokenized[\"test\"]\n",
    "joy_train_dataset, joy_eval_dataset = joy_tokenized[\"train\"], joy_tokenized[\"test\"]\n",
    "love_train_dataset, love_eval_dataset = love_tokenized[\"train\"], love_tokenized[\"test\"]\n",
    "anger_train_dataset, anger_eval_dataset = anger_tokenized[\"train\"], anger_tokenized[\"test\"]\n",
    "fear_train_dataset, fear_eval_dataset = fear_tokenized[\"train\"], fear_tokenized[\"test\"]\n",
    "surprise_train_dataset, surprise_eval_dataset = surprise_tokenized[\"train\"], surprise_tokenized[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "                    output_dir=\"./emotions\",\n",
    "                    overwrite_output_dir=True,\n",
    "#                     do_train=True,\n",
    "#                     prediction_loss_only=True,\n",
    "#                     evaluation_strategy = 'epoch',\n",
    "                    num_train_epochs=10, \n",
    "                    per_device_train_batch_size=2,\n",
    "                    per_device_eval_batch_size=4, \n",
    "                    logging_steps = 500,\n",
    "                    save_steps=500,\n",
    "                    warmup_steps=500,\n",
    "#                     save_strategy = 'epoch',\n",
    "#                     learning_rate = 0.05,\n",
    "#                     max_steps = -1,\n",
    "#                     weight_decay=0.01,\n",
    "#                     load_best_model_at_end=True,\n",
    "#                     resume_from_checkpoint = True\n",
    "#                     report_to=\"wandb\",  # enable logging to W&B\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sadness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /home/avsorokina/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_sadness = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "model_sadness.config.pad_token_id = model_sadness.config.eos_token_id\n",
    "tokenizer_sadness = AutoTokenizer.from_pretrained('gpt2') \n",
    "tokenizer_sadness.pad_token = tokenizer_sadness.eos_token\n",
    "\n",
    "data_collator_sadness = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer_sadness, mlm=False,\n",
    "    )\n",
    "trainer_sadness = Trainer(\n",
    "    model=model_sadness, args=training_args, \n",
    "    data_collator=data_collator_sadness,\n",
    "    train_dataset=sadness_train_dataset)\n",
    "trainer_sadness.train()\n",
    "\n",
    "trainer_sadness.save_model(\"emotion_fine_tuned/gpt2_sadness\")\n",
    "tokenizer_sadness.save_pretrained(\"emotion_fine_tuned/gpt2_sadness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsorokina/anaconda3/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:742: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer_sadness = AutoTokenizer.from_pretrained(\"emotion_fine_tuned/gpt2_sadness\")\n",
    "sadness_model = AutoModelWithLMHead.from_pretrained(\"emotion_fine_tuned/gpt2_sadness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_finetune_sadness = pipeline('text-generation', model=sadness_model, tokenizer=tokenizer_sadness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /home/avsorokina/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /home/avsorokina/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /home/avsorokina/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /home/avsorokina/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "***** Running training *****\n",
      "  Num examples = 5362\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 26810\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22339' max='26810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22339/26810 6:14:13 < 1:14:54, 0.99 it/s, Epoch 8.33/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.561300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.288000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.262100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.820100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.588700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.576200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.126100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>3.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.688400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.630600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.654500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>2.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.297900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>2.350700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>2.308900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>2.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.044200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>2.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>1.798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.762900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>1.785300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.806800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>1.814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.724400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>1.622900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>1.609000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>1.635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.476500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./emotions/checkpoint-500\n",
      "Configuration saved in ./emotions/checkpoint-500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1000\n",
      "Configuration saved in ./emotions/checkpoint-1000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1500\n",
      "Configuration saved in ./emotions/checkpoint-1500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2000\n",
      "Configuration saved in ./emotions/checkpoint-2000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2500\n",
      "Configuration saved in ./emotions/checkpoint-2500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2500/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ./emotions/checkpoint-10500\n",
      "Configuration saved in ./emotions/checkpoint-10500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-11000\n",
      "Configuration saved in ./emotions/checkpoint-11000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-11500\n",
      "Configuration saved in ./emotions/checkpoint-11500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-12000\n",
      "Configuration saved in ./emotions/checkpoint-12000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-12500\n",
      "Configuration saved in ./emotions/checkpoint-12500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-13000\n",
      "Configuration saved in ./emotions/checkpoint-13000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-13000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ./emotions/checkpoint-19500\n",
      "Configuration saved in ./emotions/checkpoint-19500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-19500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-20000\n",
      "Configuration saved in ./emotions/checkpoint-20000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-20000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-20500\n",
      "Configuration saved in ./emotions/checkpoint-20500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-20500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-21000\n",
      "Configuration saved in ./emotions/checkpoint-21000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-21000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-21500\n",
      "Configuration saved in ./emotions/checkpoint-21500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-21500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-22000\n",
      "Configuration saved in ./emotions/checkpoint-22000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-22000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_joy = AutoTokenizer.from_pretrained('gpt2') \n",
    "model_joy = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "model_joy.config.pad_token_id = model_joy.config.eos_token_id\n",
    "tokenizer_joy.pad_token = tokenizer_joy.eos_token\n",
    "\n",
    "data_collator_joy = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer_joy, mlm=False,\n",
    "    )\n",
    "trainer_joy = Trainer(\n",
    "    model=model_joy, \n",
    "    args=training_args, \n",
    "    data_collator=data_collator_joy,\n",
    "    train_dataset=joy_train_dataset)\n",
    "trainer_joy.train()\n",
    "\n",
    "trainer_joy.save_model(\"emotion_fine_tuned/gpt2_joy\")\n",
    "tokenizer_joy.save_pretrained(\"emotion_fine_tuned/gpt2_joy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_joy = AutoTokenizer.from_pretrained(\"emotion_fine_tuned/gpt2_joy\")\n",
    "joy_model = AutoModelWithLMHead.from_pretrained(\"emotion_fine_tuned/gpt2_joy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_finetune_joy = pipeline('text-generation', model=joy_model, tokenizer=tokenizer_joy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1304\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6520\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnastyatrvl\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nastyatrvl/huggingface/runs/fvuzr7rn\" target=\"_blank\">./emotions</a></strong> to <a href=\"https://wandb.ai/nastyatrvl/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6520' max='6520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6520/6520 1:52:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.842900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.486500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.581900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.189400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.961700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.475900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.313400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.130200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.058600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./emotions/checkpoint-500\n",
      "Configuration saved in ./emotions/checkpoint-500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1000\n",
      "Configuration saved in ./emotions/checkpoint-1000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1500\n",
      "Configuration saved in ./emotions/checkpoint-1500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2000\n",
      "Configuration saved in ./emotions/checkpoint-2000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2500\n",
      "Configuration saved in ./emotions/checkpoint-2500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-3000\n",
      "Configuration saved in ./emotions/checkpoint-3000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-3500\n",
      "Configuration saved in ./emotions/checkpoint-3500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-4000\n",
      "Configuration saved in ./emotions/checkpoint-4000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-4500\n",
      "Configuration saved in ./emotions/checkpoint-4500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-5000\n",
      "Configuration saved in ./emotions/checkpoint-5000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-5500\n",
      "Configuration saved in ./emotions/checkpoint-5500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-6000\n",
      "Configuration saved in ./emotions/checkpoint-6000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-6500\n",
      "Configuration saved in ./emotions/checkpoint-6500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-6500/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to emotion_fine_tuned/gpt2_love\n",
      "Configuration saved in emotion_fine_tuned/gpt2_love/config.json\n",
      "Model weights saved in emotion_fine_tuned/gpt2_love/pytorch_model.bin\n",
      "tokenizer config file saved in emotion_fine_tuned/gpt2_love/tokenizer_config.json\n",
      "Special tokens file saved in emotion_fine_tuned/gpt2_love/special_tokens_map.json\n",
      "Didn't find file emotion_fine_tuned/gpt2_love/added_tokens.json. We won't load it.\n",
      "loading file emotion_fine_tuned/gpt2_love/vocab.json\n",
      "loading file emotion_fine_tuned/gpt2_love/merges.txt\n",
      "loading file emotion_fine_tuned/gpt2_love/tokenizer.json\n",
      "loading file None\n",
      "loading file emotion_fine_tuned/gpt2_love/special_tokens_map.json\n",
      "loading file emotion_fine_tuned/gpt2_love/tokenizer_config.json\n",
      "/home/avsorokina/anaconda3/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:742: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "loading configuration file emotion_fine_tuned/gpt2_love/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"emotion_fine_tuned/gpt2_love\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file emotion_fine_tuned/gpt2_love/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at emotion_fine_tuned/gpt2_love.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_love = AutoTokenizer.from_pretrained('gpt2') \n",
    "model_love = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "model_love.config.pad_token_id = model_love.config.eos_token_id\n",
    "tokenizer_love.pad_token = tokenizer_love.eos_token\n",
    "\n",
    "data_collator_love = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer_love, mlm=False,\n",
    "    )\n",
    "trainer_love = Trainer(\n",
    "    model=model_love, \n",
    "    args=training_args, \n",
    "    data_collator=data_collator_love,\n",
    "    train_dataset=love_train_dataset)\n",
    "trainer_love.train()\n",
    "\n",
    "trainer_love.save_model(\"emotion_fine_tuned/gpt2_love\")\n",
    "tokenizer_love.save_pretrained(\"emotion_fine_tuned/gpt2_love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_love = AutoTokenizer.from_pretrained(\"emotion_fine_tuned/gpt2_love\")\n",
    "love_model = AutoModelWithLMHead.from_pretrained(\"emotion_fine_tuned/gpt2_love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_finetune_love = pipeline('text-generation', model=love_model, tokenizer=tokenizer_love)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /home/avsorokina/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /home/avsorokina/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /home/avsorokina/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /home/avsorokina/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "***** Running training *****\n",
      "  Num examples = 1937\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9690\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9639' max='9690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9639/9690 2:20:49 < 00:44, 1.14 it/s, Epoch 9.95/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.593400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.491600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.420600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.767300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.367900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.322400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.253800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.179400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./emotions/checkpoint-500\n",
      "Configuration saved in ./emotions/checkpoint-500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1000\n",
      "Configuration saved in ./emotions/checkpoint-1000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1500\n",
      "Configuration saved in ./emotions/checkpoint-1500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2000\n",
      "Configuration saved in ./emotions/checkpoint-2000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2500\n",
      "Configuration saved in ./emotions/checkpoint-2500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-3000\n",
      "Configuration saved in ./emotions/checkpoint-3000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-3500\n",
      "Configuration saved in ./emotions/checkpoint-3500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-4000\n",
      "Configuration saved in ./emotions/checkpoint-4000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-4500\n",
      "Configuration saved in ./emotions/checkpoint-4500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-5000\n",
      "Configuration saved in ./emotions/checkpoint-5000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-5500\n",
      "Configuration saved in ./emotions/checkpoint-5500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-6000\n",
      "Configuration saved in ./emotions/checkpoint-6000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-6500\n",
      "Configuration saved in ./emotions/checkpoint-6500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-7000\n",
      "Configuration saved in ./emotions/checkpoint-7000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-7500\n",
      "Configuration saved in ./emotions/checkpoint-7500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-8000\n",
      "Configuration saved in ./emotions/checkpoint-8000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-8500\n",
      "Configuration saved in ./emotions/checkpoint-8500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-9000\n",
      "Configuration saved in ./emotions/checkpoint-9000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-9500\n",
      "Configuration saved in ./emotions/checkpoint-9500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-9500/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "tokenizer_fear = AutoTokenizer.from_pretrained('gpt2') \n",
    "model_fear = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "model_fear.config.pad_token_id = model_fear.config.eos_token_id\n",
    "tokenizer_fear.pad_token = tokenizer_fear.eos_token\n",
    "\n",
    "data_collator_fear = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer_fear, mlm=False,\n",
    "    )\n",
    "trainer_fear = Trainer(\n",
    "    model=model_fear, \n",
    "    args=training_args, \n",
    "    data_collator=data_collator_fear,\n",
    "    train_dataset=fear_train_dataset)\n",
    "trainer_fear.train()\n",
    "\n",
    "trainer_fear.save_model(\"emotion_fine_tuned/gpt2_fear\")\n",
    "tokenizer_fear.save_pretrained(\"emotion_fine_tuned/gpt2_fear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_fear = AutoTokenizer.from_pretrained(\"emotion_fine_tuned/gpt2_fear\")\n",
    "fear_model = AutoModelWithLMHead.from_pretrained(\"emotion_fine_tuned/gpt2_fear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_finetune_fear = pipeline('text-generation', model=fear_model, tokenizer=tokenizer_fear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /home/avsorokina/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /home/avsorokina/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /home/avsorokina/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/avsorokina/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /home/avsorokina/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "***** Running training *****\n",
      "  Num examples = 572\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2860\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2860' max='2860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2860/2860 39:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.313800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.396400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.222900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./emotions/checkpoint-500\n",
      "Configuration saved in ./emotions/checkpoint-500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1000\n",
      "Configuration saved in ./emotions/checkpoint-1000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-1500\n",
      "Configuration saved in ./emotions/checkpoint-1500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2000\n",
      "Configuration saved in ./emotions/checkpoint-2000/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ./emotions/checkpoint-2500\n",
      "Configuration saved in ./emotions/checkpoint-2500/config.json\n",
      "Model weights saved in ./emotions/checkpoint-2500/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to emotion_fine_tuned/gpt2_surprise\n",
      "Configuration saved in emotion_fine_tuned/gpt2_surprise/config.json\n",
      "Model weights saved in emotion_fine_tuned/gpt2_surprise/pytorch_model.bin\n",
      "tokenizer config file saved in emotion_fine_tuned/gpt2_surprise/tokenizer_config.json\n",
      "Special tokens file saved in emotion_fine_tuned/gpt2_surprise/special_tokens_map.json\n",
      "Didn't find file emotion_fine_tuned/gpt2_surprise/added_tokens.json. We won't load it.\n",
      "loading file emotion_fine_tuned/gpt2_surprise/vocab.json\n",
      "loading file emotion_fine_tuned/gpt2_surprise/merges.txt\n",
      "loading file emotion_fine_tuned/gpt2_surprise/tokenizer.json\n",
      "loading file None\n",
      "loading file emotion_fine_tuned/gpt2_surprise/special_tokens_map.json\n",
      "loading file emotion_fine_tuned/gpt2_surprise/tokenizer_config.json\n",
      "/home/avsorokina/anaconda3/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:742: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "loading configuration file emotion_fine_tuned/gpt2_surprise/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"emotion_fine_tuned/gpt2_surprise\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file emotion_fine_tuned/gpt2_surprise/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at emotion_fine_tuned/gpt2_surprise.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_surprise = AutoTokenizer.from_pretrained('gpt2') \n",
    "model_surprise = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "model_surprise.config.pad_token_id = model_surprise.config.eos_token_id\n",
    "tokenizer_surprise.pad_token = tokenizer_surprise.eos_token\n",
    "\n",
    "data_collator_surprise = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer_surprise, mlm=False,\n",
    "    )\n",
    "trainer_surprise = Trainer(\n",
    "    model=model_surprise, \n",
    "    args=training_args, \n",
    "    data_collator=data_collator_surprise,\n",
    "    train_dataset=surprise_train_dataset)\n",
    "trainer_surprise.train()\n",
    "\n",
    "trainer_surprise.save_model(\"emotion_fine_tuned/gpt2_surprise\")\n",
    "tokenizer_surprise.save_pretrained(\"emotion_fine_tuned/gpt2_surprise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_surprise = AutoTokenizer.from_pretrained(\"emotion_fine_tuned/gpt2_surprise\")\n",
    "surprise_model = AutoModelWithLMHead.from_pretrained(\"emotion_fine_tuned/gpt2_surprise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_finetune_surprise = pipeline('text-generation', model=surprise_model, tokenizer=tokenizer_surprise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_anger = AutoTokenizer.from_pretrained('gpt2') \n",
    "model_anger = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "model_anger.config.pad_token_id = model_anger.config.eos_token_id\n",
    "tokenizer_anger.pad_token = tokenizer_anger.eos_token\n",
    "\n",
    "data_collator_anger = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer_anger, mlm=False,\n",
    "    )\n",
    "trainer_anger = Trainer(\n",
    "    model=model_anger, \n",
    "    args=training_args, \n",
    "    data_collator=data_collator_anger,\n",
    "    train_dataset=anger_train_dataset)\n",
    "trainer_anger.train()\n",
    "\n",
    "trainer_anger.save_model(\"emotion_fine_tuned/gpt2_anger\")\n",
    "tokenizer_anger.save_pretrained(\"emotion_fine_tuned/gpt2_anger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_anger = AutoTokenizer.from_pretrained(\"emotion_fine_tuned/gpt2_anger\")\n",
    "anger_model = AutoModelWithLMHead.from_pretrained(\"emotion_fine_tuned/gpt2_anger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_finetune_anger = pipeline('text-generation', model=anger_model, tokenizer=tokenizer_anger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = [\"I am \",\n",
    "             \"I think that\",\n",
    "             \"I like\",\n",
    "             \"I don't like\",\n",
    "             \"I want\",\n",
    "             \"My dream is\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\",model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404 Client Error: Not Found for url: https://huggingface.co/arpanghoshal/EmoRoBERTa/resolve/main/pytorch_model.bin\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier2 = pipeline(\"text-classification\",model='arpanghoshal/EmoRoBERTa', return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am ive been feeling pretty grumpy lately with school work so i figured it would be a good time to get my hackles up about that too ehb? hmmmmm what is school do britain if youre into film study \n",
      "\n",
      " {'label': 'anger', 'score': 0.9981691837310791} \n",
      "\n",
      " {'label': 'realization', 'score': 0.9645422101020813}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that feeling dissatisfied with my life transformed into this state where i am miserable and depressed about everything most of the time even though i have been through a lot without much change in me or at least not much satisfaction yet again because all i ever want \n",
      "\n",
      " {'label': 'anger', 'score': 0.9977060556411743} \n",
      "\n",
      " {'label': 'disappointment', 'score': 0.9583703279495239}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like to buck the system and climb on my soapbox when i feel wronged or see others wronged but lately i feel very much dissatisfied with how society has turned around me as a result of some illogically poor choices many people make in \n",
      "\n",
      " {'label': 'anger', 'score': 0.9980353713035583} \n",
      "\n",
      " {'label': 'approval', 'score': 0.8349703550338745}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like feeling rushed and exhausted when i have new music and new lyrics that clearly have nothing to do with each other or my life anymore because at the moment im stuck in traffic for a few monthe ago so that my normal moods don \n",
      "\n",
      " {'label': 'anger', 'score': 0.9978049397468567} \n",
      "\n",
      " {'label': 'realization', 'score': 0.3490718901157379}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I want to feel like i was wronged but it gets back ugly and all those petty resentments that used to keep me up at night trying not to cry or think about what am I doing to deserve that praise instead of gratitude from you in return \n",
      "\n",
      " {'label': 'anger', 'score': 0.9980378746986389} \n",
      "\n",
      " {'label': 'annoyance', 'score': 0.6066219806671143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is so simple but so unrealistic i feel enraged that i want to run away from it all together with my sister and her family members as soon possible after they have left for good reasons why do i care so much about this dream no matter how \n",
      "\n",
      " {'label': 'anger', 'score': 0.9974644184112549} \n",
      "\n",
      " {'label': 'anger', 'score': 0.971961498260498}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt in test_prompts:\n",
    "    res = gpt2_finetune_anger(text_inputs=prompt, \n",
    "                      top_k = 50,\n",
    "                      top_p = 0.95,\n",
    "                      no_repeat_ngram_size = 3,  \n",
    "                      repetition_penalty=1.2,\n",
    "                      max_length = 50,\n",
    "                      temperature = 0.7)\n",
    "    prediction1 = classifier(res[0]['generated_text'])\n",
    "    prediction2 = classifier2(res[0]['generated_text'])\n",
    "    prediction1 = sorted(prediction1[0], key=lambda d: d['score'], reverse = True) \n",
    "    prediction2 = sorted(prediction2[0], key=lambda d: d['score'], reverse = True) \n",
    "    print(res[0]['generated_text'], 2*\"\\n\", prediction1[0], 2*\"\\n\", prediction2[0])\n",
    "    print(100*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am ive always felt that i couldnt be more appreciative of people who made me feel unhappy than the ones we all have to think twice \n",
      "\n",
      " {'label': 'sadness', 'score': 0.9982587695121765} \n",
      "\n",
      " {'label': 'disappointment', 'score': 0.667558491230011}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that s how we should feel when something big has happened in our life and it feels like things are getting resolved a bit too quickly for this \n",
      "\n",
      " {'label': 'joy', 'score': 0.9986312985420227} \n",
      "\n",
      " {'label': 'approval', 'score': 0.6539403200149536}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like to listen and feel entertained by the singers since i know they are so popular but as a group effort it feels like a chore not being present \n",
      "\n",
      " {'label': 'joy', 'score': 0.9989572763442993} \n",
      "\n",
      " {'label': 'joy', 'score': 0.9555159211158752}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like to feel judged because i think i look pretty in women s clothing and sometimes i even want a little bit of solace from the \n",
      "\n",
      " {'label': 'joy', 'score': 0.9744322896003723} \n",
      "\n",
      " {'label': 'approval', 'score': 0.4164397716522217}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I want to feel respected by people i know well and get a license yes thats how my parents taught me always being respectful so if anyone feels slight or \n",
      "\n",
      " {'label': 'joy', 'score': 0.9987928867340088} \n",
      "\n",
      " {'label': 'approval', 'score': 0.4963292181491852}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is to be able sit and feel the pleasant tug at my muscles under the deep cool air with a precision that will make me appreciate what i \n",
      "\n",
      " {'label': 'joy', 'score': 0.999015212059021} \n",
      "\n",
      " {'label': 'admiration', 'score': 0.8668373823165894}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt in test_prompts:\n",
    "    res = gpt2_finetune_joy(text_inputs=prompt, \n",
    "                      top_k = 50,\n",
    "                      top_p = 0.95,\n",
    "                      no_repeat_ngram_size = 3,  \n",
    "                      repetition_penalty=1.2,\n",
    "                      max_length = 30,\n",
    "                      temperature = 0.7)\n",
    "    prediction1 = classifier(res[0]['generated_text'])\n",
    "    prediction2 = classifier2(res[0]['generated_text'])\n",
    "    prediction1 = sorted(prediction1[0], key=lambda d: d['score'], reverse = True) \n",
    "    prediction2 = sorted(prediction2[0], key=lambda d: d['score'], reverse = True) \n",
    "    print(res[0]['generated_text'], 2*\"\\n\", prediction1[0], 2*\"\\n\", prediction2[0])\n",
    "    print(100*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am ive been feeling a bit nostalgic lately because i m no longer trying to rekindle some sort of nostalgia craze in my life but rather rather ively rekindling the desire for something more than just another piece back to the family \n",
      "\n",
      " {'label': 'love', 'score': 0.9944379329681396} \n",
      "\n",
      " {'label': 'realization', 'score': 0.8780173063278198}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that the woman in front of me should have said no way and if she feels like telling a stranger this is what kind people feel towards them it will be treated with dignity and respect as though i gave myself permission to enter into some sort contract \n",
      "\n",
      " {'label': 'joy', 'score': 0.5518168807029724} \n",
      "\n",
      " {'label': 'realization', 'score': 0.595809817314148}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like to do it makes me feel very out of control but sometimes i just have to get in and take care if i want a baby formula or not which is expensive haha so impulse buying habits aside its easy since im the only one whos using \n",
      "\n",
      " {'label': 'joy', 'score': 0.9838606119155884} \n",
      "\n",
      " {'label': 'amusement', 'score': 0.5520778298377991}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like the way things are but i feel that they should be supportive of each other rather than trying to shove people into situations where there is none and everything just feels very cliche so why not give them a sympathetic ear when in fact we \n",
      "\n",
      " {'label': 'love', 'score': 0.9952744245529175} \n",
      "\n",
      " {'label': 'disapproval', 'score': 0.9586798548698425}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I want to know and feel loved long after first sighted heaven and earth for the words i have sought but never knew god has given me permission to utter those illusory promises nor am I likely to be accord that heavenly calling in return.\"  \n",
      "\n",
      " {'label': 'love', 'score': 0.9948902130126953} \n",
      "\n",
      " {'label': 'desire', 'score': 0.6897903680801392}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is that i will be able to go back and look at all the photos of my lovely girls just like those which are so sweet to have on display at such a young age and remember them when they were little ones who made me feel tre \n",
      "\n",
      " {'label': 'love', 'score': 0.9894002079963684} \n",
      "\n",
      " {'label': 'joy', 'score': 0.43753206729888916}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt in test_prompts:\n",
    "    res = gpt2_finetune_love(text_inputs=prompt, \n",
    "                      top_k = 50,\n",
    "                      top_p = 0.95,\n",
    "                      no_repeat_ngram_size = 3,  \n",
    "                      repetition_penalty=1.2,\n",
    "                      max_length = 50,\n",
    "                      temperature = 0.7)\n",
    "    prediction1 = classifier(res[0]['generated_text'])\n",
    "    prediction2 = classifier2(res[0]['generated_text'])\n",
    "    prediction1 = sorted(prediction1[0], key=lambda d: d['score'], reverse = True) \n",
    "    prediction2 = sorted(prediction2[0], key=lambda d: d['score'], reverse = True) \n",
    "    print(res[0]['generated_text'], 2*\"\\n\", prediction1[0], 2*\"\\n\", prediction2[0])\n",
    "    print(100*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prompt in test_prompts:\n",
    "#     print(gpt2_finetune_joy2(text_inputs=prompt, \n",
    "#                       top_k = 50,\n",
    "#                       top_p = 0.95,\n",
    "#                       no_repeat_ngram_size = 3,  \n",
    "#                       repetition_penalty=1.2,\n",
    "#                       max_length = 50,\n",
    "#                       temperature = 0.7)\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am ive always felt amazed by how they can do something once i started to follow a set of food rules and adapt quickly without any trouble or stressor while balancing out my calorie needs efficiently with what is left over from the day we were here \n",
      "\n",
      " {'label': 'surprise', 'score': 0.9907650947570801} \n",
      "\n",
      " {'label': 'surprise', 'score': 0.9749290347099304}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that after all these years it still feels strange to realize how much i inspired people through my work and the friendships I made throughout this amazing life. ive always wanted to be a part of something bigger than myself but now im just waking up \n",
      "\n",
      " {'label': 'surprise', 'score': 0.8423177599906921} \n",
      "\n",
      " {'label': 'realization', 'score': 0.9772616624832153}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like to do things that leave others feeling amazed and delighted while still respecting the source code of our company which is based in open society far away from us by providing continuous access through a simple website www.opensourcecompanyfoundationprojectcdn.net or \n",
      "\n",
      " {'label': 'surprise', 'score': 0.9884616136550903} \n",
      "\n",
      " {'label': 'approval', 'score': 0.933809757232666}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like to admit that i sometimes feel a little weird having my name called upon me by people who are less religious or have more skin in the game than I do and this is something of god but it s not always easy for someone with \n",
      "\n",
      " {'label': 'surprise', 'score': 0.6196061372756958} \n",
      "\n",
      " {'label': 'disapproval', 'score': 0.6898221969604492}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I want to feel amazed at the miracles around me daily and also realize that i am blessed with a unique calling which is shared by all of us who are members of this family. ive always felt called a spiritual father but now im surrounded by people \n",
      "\n",
      " {'label': 'surprise', 'score': 0.9911750555038452} \n",
      "\n",
      " {'label': 'realization', 'score': 0.9767499566078186}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is that someone who listens will give me something to do when i feel overwhelmed or am needing help finding a job and waking up with nothing but the feeling of exhausted tired bodies all over my body trying not think about it again until im totally fat \n",
      "\n",
      " {'label': 'surprise', 'score': 0.5044137239456177} \n",
      "\n",
      " {'label': 'desire', 'score': 0.7580239772796631}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt in test_prompts:\n",
    "    res = gpt2_finetune_surprise(text_inputs=prompt, \n",
    "                      top_k = 50,\n",
    "                      top_p = 0.95,\n",
    "                      no_repeat_ngram_size = 3,  \n",
    "                      repetition_penalty=1.2,\n",
    "                      max_length = 50,\n",
    "                      temperature = 0.7)\n",
    "    prediction1 = classifier(res[0]['generated_text'])\n",
    "    prediction2 = classifier2(res[0]['generated_text'])\n",
    "    prediction1 = sorted(prediction1[0], key=lambda d: d['score'], reverse = True) \n",
    "    prediction2 = sorted(prediction2[0], key=lambda d: d['score'], reverse = True) \n",
    "    print(res[0]['generated_text'], 2*\"\\n\", prediction1[0], 2*\"\\n\", prediction2[0])\n",
    "    print(100*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am ive had so many bad experiences that i feel intimidated to write about them here because ill be too busy to bother with the rest of this post at all times and want you guys to know how ive gone through the tough moments before coming \n",
      "\n",
      " {'label': 'fear', 'score': 0.997031569480896} \n",
      "\n",
      " {'label': 'fear', 'score': 0.9451883435249329}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I think that the main benefit of using a clinique product is having an easy way to add more products without feeling pressured to because there are so many others out there who share my vision and feel like they need it for their work life balance or if \n",
      "\n",
      " {'label': 'fear', 'score': 0.9976527094841003} \n",
      "\n",
      " {'label': 'approval', 'score': 0.9627368450164795}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I like to add some cute photos from today as well so i can keep doing what i am doing and not feel shy anymore while typing this out in my notebook or on the wall when im at work all day long without writing anything else at all lol \n",
      "\n",
      " {'label': 'fear', 'score': 0.9970971345901489} \n",
      "\n",
      " {'label': 'amusement', 'score': 0.7258996963500977}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I don't like feeling unsure about something i can only assume that it is a result of my own shortcomings rather than the product s fault or design of someone else s work environment either way its just me making assumptions based on what seems to be the default \n",
      "\n",
      " {'label': 'fear', 'score': 0.9975717663764954} \n",
      "\n",
      " {'label': 'disapproval', 'score': 0.4833192527294159}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I want to be able t sing and talk and feel absolutely terrified of falling off the cliff face without feeling exactly as scared i felt at that point in my career when i started crunched up such an epic number crunching down with my hands crossed \n",
      "\n",
      " {'label': 'fear', 'score': 0.9975572824478149} \n",
      "\n",
      " {'label': 'fear', 'score': 0.8791913986206055}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "My dream is that it was a bad dream but i remember waking up in the middle of the night knowing that my friend Sandy had been raped and murdered by some of our very best people including my great great granddaughters plus i remember feeling terrified as \n",
      "\n",
      " {'label': 'fear', 'score': 0.9976525902748108} \n",
      "\n",
      " {'label': 'fear', 'score': 0.9833078384399414}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt in test_prompts:\n",
    "    res = gpt2_finetune_fear(text_inputs=prompt, \n",
    "                      top_k = 50,\n",
    "                      top_p = 0.95,\n",
    "                      no_repeat_ngram_size = 3,  \n",
    "                      repetition_penalty=1.2,\n",
    "                      max_length = 50,\n",
    "                      temperature = 0.7)\n",
    "    prediction1 = classifier(res[0]['generated_text'])\n",
    "    prediction2 = classifier2(res[0]['generated_text'])\n",
    "    prediction1 = sorted(prediction1[0], key=lambda d: d['score'], reverse = True) \n",
    "    prediction2 = sorted(prediction2[0], key=lambda d: d['score'], reverse = True) \n",
    "    print(res[0]['generated_text'], 2*\"\\n\", prediction1[0], 2*\"\\n\", prediction2[0])\n",
    "    print(100*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
